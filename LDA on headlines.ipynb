{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-25T03:40:42.617001Z",
     "iopub.status.busy": "2021-05-25T03:40:42.616681Z",
     "iopub.status.idle": "2021-05-25T03:40:42.631044Z",
     "shell.execute_reply": "2021-05-25T03:40:42.630368Z",
     "shell.execute_reply.started": "2021-05-25T03:40:42.616936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/million-headlines/abcnews-date-text.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, load and examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:42:33.933794Z",
     "iopub.status.busy": "2021-05-26T03:42:33.933322Z",
     "iopub.status.idle": "2021-05-26T03:42:36.041500Z",
     "shell.execute_reply": "2021-05-26T03:42:36.040730Z",
     "shell.execute_reply.started": "2021-05-26T03:42:33.933752Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/million-headlines/abcnews-date-text.csv', error_bad_lines=False)\n",
    "data['publish_date'] = pd.to_datetime(data.publish_date, format='%Y%m%d')\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T03:46:52.302272Z",
     "iopub.status.busy": "2021-05-25T03:46:52.301952Z",
     "iopub.status.idle": "2021-05-25T03:46:52.312046Z",
     "shell.execute_reply": "2021-05-25T03:46:52.311148Z",
     "shell.execute_reply.started": "2021-05-25T03:46:52.302244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-02-19</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                      headline_text\n",
       "0   2003-02-19  aba decides against community broadcasting lic...\n",
       "1   2003-02-19     act fire witnesses must be aware of defamation\n",
       "2   2003-02-19     a g calls for infrastructure protection summit\n",
       "3   2003-02-19           air nz staff in aust strike for pay rise\n",
       "4   2003-02-19      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T03:51:17.219967Z",
     "iopub.status.busy": "2021-05-25T03:51:17.219492Z",
     "iopub.status.idle": "2021-05-25T03:51:18.664560Z",
     "shell.execute_reply": "2021-05-25T03:51:18.663584Z",
     "shell.execute_reply.started": "2021-05-25T03:51:17.219938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1226258</td>\n",
       "      <td>1226258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6517</td>\n",
       "      <td>1195191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2012-08-24 00:00:00</td>\n",
       "      <td>national rural news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>384</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2003-02-19 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2020-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               publish_date        headline_text\n",
       "count               1226258              1226258\n",
       "unique                 6517              1195191\n",
       "top     2012-08-24 00:00:00  national rural news\n",
       "freq                    384                  983\n",
       "first   2003-02-19 00:00:00                  NaN\n",
       "last    2020-12-31 00:00:00                  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T03:47:23.141237Z",
     "iopub.status.busy": "2021-05-25T03:47:23.140981Z",
     "iopub.status.idle": "2021-05-25T03:47:23.150091Z",
     "shell.execute_reply": "2021-05-25T03:47:23.149237Z",
     "shell.execute_reply.started": "2021-05-25T03:47:23.141215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text  index\n",
       "0  aba decides against community broadcasting lic...      0\n",
       "1     act fire witnesses must be aware of defamation      1\n",
       "2     a g calls for infrastructure protection summit      2\n",
       "3           air nz staff in aust strike for pay rise      3\n",
       "4      air nz strike to affect australian travellers      4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprossing \n",
    "* Tokenization: Split the headline text into sentences and sentences into words. Lowercase the words and remove punctuation\n",
    "* Words that have fewer than 3 characters are removed\n",
    "* All stopwords are removed\n",
    "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present\n",
    "* Words are stemmed — words are reduced to their root form (plural to single) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:42:44.545818Z",
     "iopub.status.busy": "2021-05-26T03:42:44.545364Z",
     "iopub.status.idle": "2021-05-26T03:42:46.818458Z",
     "shell.execute_reply": "2021-05-26T03:42:46.817325Z",
     "shell.execute_reply.started": "2021-05-26T03:42:44.545788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T04:00:32.855679Z",
     "iopub.status.busy": "2021-05-25T04:00:32.855328Z",
     "iopub.status.idle": "2021-05-25T04:00:32.861261Z",
     "shell.execute_reply": "2021-05-25T04:00:32.859676Z",
     "shell.execute_reply.started": "2021-05-25T04:00:32.855655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "# An example of lemmatisation \n",
    "print(WordNetLemmatizer().lemmatize('gone', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:42:59.887371Z",
     "iopub.status.busy": "2021-05-26T03:42:59.886873Z",
     "iopub.status.idle": "2021-05-26T03:42:59.909532Z",
     "shell.execute_reply": "2021-05-26T03:42:59.908692Z",
     "shell.execute_reply.started": "2021-05-26T03:42:59.887340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of stemming \n",
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:43:04.422183Z",
     "iopub.status.busy": "2021-05-26T03:43:04.421737Z",
     "iopub.status.idle": "2021-05-26T03:43:04.427264Z",
     "shell.execute_reply": "2021-05-26T03:43:04.426332Z",
     "shell.execute_reply.started": "2021-05-26T03:43:04.422145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that puts together lemmatisation and stemming \n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:43:06.763861Z",
     "iopub.status.busy": "2021-05-26T03:43:06.763545Z",
     "iopub.status.idle": "2021-05-26T03:43:06.768273Z",
     "shell.execute_reply": "2021-05-26T03:43:06.767643Z",
     "shell.execute_reply.started": "2021-05-26T03:43:06.763833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to split sentences into words, remove stopwords and any words that have less than 3 characters \n",
    "# Pass the result into the lemmatize_stemming function defined above to retrieve its root form\n",
    "STOPWORDS = gensim.parsing.preprocessing.STOPWORDS\n",
    "def preprocess(headline):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(headline):\n",
    "        if token not in STOPWORDS and len(token) >= 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T04:15:22.640520Z",
     "iopub.status.busy": "2021-05-25T04:15:22.639955Z",
     "iopub.status.idle": "2021-05-25T04:15:22.651480Z",
     "shell.execute_reply": "2021-05-25T04:15:22.650286Z",
     "shell.execute_reply.started": "2021-05-25T04:15:22.640471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['poultry', 'firm', 'drops', 'building', 'buy', 'plan']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['poultri', 'firm', 'drop', 'build', 'buy', 'plan']\n"
     ]
    }
   ],
   "source": [
    "# Test whether the function works or not \n",
    "doc_sample = documents[documents['index'] == 4300].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T03:43:16.689862Z",
     "iopub.status.busy": "2021-05-26T03:43:16.689407Z",
     "iopub.status.idle": "2021-05-26T03:46:18.766428Z",
     "shell.execute_reply": "2021-05-26T03:46:18.765576Z",
     "shell.execute_reply.started": "2021-05-26T03:43:16.689834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original headline</th>\n",
       "      <th>Processed headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>[aba, decid, communiti, broadcast, licenc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>[act, wit, awar, defam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>[call, infrastructur, protect, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>[air, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>[air, strike, affect, australian, travel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original headline  \\\n",
       "0  aba decides against community broadcasting lic...   \n",
       "1     act fire witnesses must be aware of defamation   \n",
       "2     a g calls for infrastructure protection summit   \n",
       "3           air nz staff in aust strike for pay rise   \n",
       "4      air nz strike to affect australian travellers   \n",
       "\n",
       "                           Processed headline  \n",
       "0  [aba, decid, communiti, broadcast, licenc]  \n",
       "1                     [act, wit, awar, defam]  \n",
       "2      [call, infrastructur, protect, summit]  \n",
       "3       [air, staff, aust, strike, pay, rise]  \n",
       "4   [air, strike, affect, australian, travel]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_docs = documents.headline_text.map(preprocess)\n",
    "pd.DataFrame(data = {'Original headline': documents.headline_text[:5], 'Processed headline': preprocess_docs[:5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bag of Words \n",
    "* Create a word dictionary where unqiue words across all documents are represented by unique indexes \n",
    "* Since there are lots of unique words, we filter out words that are either too common or too rare \n",
    "* Count the number of times a word appears for each headline \n",
    "  * Example: [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)] for the first headline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:21:20.099268Z",
     "iopub.status.busy": "2021-05-26T04:21:20.098860Z",
     "iopub.status.idle": "2021-05-26T04:21:41.411739Z",
     "shell.execute_reply": "2021-05-26T04:21:41.410818Z",
     "shell.execute_reply.started": "2021-05-26T04:21:20.099236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 aba\n",
      "1 broadcast\n",
      "2 communiti\n",
      "3 decid\n",
      "4 licenc\n",
      "5 act\n"
     ]
    }
   ],
   "source": [
    "# create a word dictionary where unique words in all headlines are represented by unique indexes \n",
    "word_dict = gensim.corpora.Dictionary(preprocess_docs)\n",
    "# print the first 5 words in this word dictionary \n",
    "count = 0 \n",
    "for index, word in word_dict.iteritems():\n",
    "    print(index, word)\n",
    "    count+=1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:24:00.582249Z",
     "iopub.status.busy": "2021-05-26T04:24:00.581882Z",
     "iopub.status.idle": "2021-05-26T04:24:00.759477Z",
     "shell.execute_reply": "2021-05-26T04:24:00.758688Z",
     "shell.execute_reply.started": "2021-05-26T04:24:00.582220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word dictionary before filtering is 71559\n",
      "length of word dictionary after filtering is 15952\n"
     ]
    }
   ],
   "source": [
    "# Filter out tokens that appear in\n",
    "# less than 15 documents (absolute number) or\n",
    "# more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "# after the above two steps, keep only the first 100000 most frequent tokens\n",
    "print(\"length of word dictionary before filtering is {}\".format(len(word_dict)))\n",
    "word_dict.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "print(\"length of word dictionary after filtering is {}\".format(len(word_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:27:31.244904Z",
     "iopub.status.busy": "2021-05-26T04:27:31.244561Z",
     "iopub.status.idle": "2021-05-26T04:27:43.217857Z",
     "shell.execute_reply": "2021-05-26T04:27:43.216746Z",
     "shell.execute_reply.started": "2021-05-26T04:27:31.244876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 173 (\"govt\") appears 1 time in document 4310.\n",
      "Word 259 (\"group\") appears 1 time in document 4310.\n",
      "Word 311 (\"vote\") appears 1 time in document 4310.\n",
      "Word 633 (\"local\") appears 1 time in document 4310.\n",
      "Word 895 (\"want\") appears 1 time in document 4310.\n",
      "Word 3742 (\"compulsori\") appears 1 time in document 4310.\n",
      "Word 3743 (\"ratepay\") appears 1 time in document 4310.\n"
     ]
    }
   ],
   "source": [
    "# Count word frequency \n",
    "bow_corpus = [word_dict.doc2bow(doc) for doc in preprocess_docs]\n",
    "# Take document 4310 as an example \n",
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time in document 4310.\".format(bow_doc_4310[i][0], \n",
    "                                                     word_dict[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:28:40.350456Z",
     "iopub.status.busy": "2021-05-26T04:28:40.349927Z",
     "iopub.status.idle": "2021-05-26T04:28:40.357125Z",
     "shell.execute_reply": "2021-05-26T04:28:40.356165Z",
     "shell.execute_reply.started": "2021-05-26T04:28:40.350422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)],\n",
       " [(13, 1), (18, 1), (19, 1), (20, 1), (21, 1)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine word counts on the first 5 headlines \n",
    "bow_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Transformation\n",
    "\n",
    "* Use TF-IDF to assign more weights on words that are only unique to a headline and put less weights on words that are common across all headlines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:43:48.603095Z",
     "iopub.status.busy": "2021-05-26T04:43:48.602502Z",
     "iopub.status.idle": "2021-05-26T04:43:50.802491Z",
     "shell.execute_reply": "2021-05-26T04:43:50.801383Z",
     "shell.execute_reply.started": "2021-05-26T04:43:48.603045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5961221629567331),\n",
      " (1, 0.4691066873890528),\n",
      " (2, 0.31151361288073415),\n",
      " (3, 0.4021230894767581),\n",
      " (4, 0.4072266845116059)]\n",
      "[(5, 0.3782290788329865),\n",
      " (6, 0.5556888380919022),\n",
      " (7, 0.5701091938749195),\n",
      " (8, 0.47236446331674)]\n",
      "[(9, 0.38317854322330597),\n",
      " (10, 0.5642748994658622),\n",
      " (11, 0.4730298749725829),\n",
      " (12, 0.5576834041187516)]\n",
      "[(13, 0.41285477758966027),\n",
      " (14, 0.44167870536827114),\n",
      " (15, 0.3851962507305321),\n",
      " (16, 0.35945495237039954),\n",
      " (17, 0.44280111873520456),\n",
      " (18, 0.4010162200360306)]\n",
      "[(13, 0.4355460552411905),\n",
      " (18, 0.4230568282245323),\n",
      " (19, 0.5127865974620833),\n",
      " (20, 0.3446105674086784),\n",
      " (21, 0.49961586859302676)]\n"
     ]
    }
   ],
   "source": [
    "# Run ti-idf on bag of words \n",
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "# Examine word frequency on first 5 headlines \n",
    "count = 0\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    count+=1\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run LDA on TF-IDF\n",
    "\n",
    "* Classify all headlines into 10 topics (10 is an arbitrary number) \n",
    "* Extract words and associated probabilities that defined the topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T04:55:36.365406Z",
     "iopub.status.busy": "2021-05-26T04:55:36.365038Z",
     "iopub.status.idle": "2021-05-26T05:00:56.933353Z",
     "shell.execute_reply": "2021-05-26T05:00:56.932207Z",
     "shell.execute_reply.started": "2021-05-26T04:55:36.365371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.010*\"royal\" + 0.010*\"elect\" + 0.008*\"commiss\" + 0.007*\"financ\" + 0.007*\"scott\" + 0.007*\"lockdown\" + 0.007*\"david\" + 0.006*\"explain\" + 0.006*\"liber\" + 0.006*\"feder\"\n",
      "Topic: 1 Word: 0.021*\"man\" + 0.018*\"polic\" + 0.015*\"charg\" + 0.013*\"murder\" + 0.012*\"woman\" + 0.011*\"crash\" + 0.010*\"court\" + 0.009*\"alleg\" + 0.009*\"death\" + 0.009*\"car\"\n",
      "Topic: 2 Word: 0.016*\"coast\" + 0.016*\"north\" + 0.016*\"south\" + 0.015*\"interview\" + 0.011*\"gold\" + 0.010*\"west\" + 0.008*\"queensland\" + 0.007*\"korea\" + 0.007*\"australia\" + 0.006*\"daniel\"\n",
      "Topic: 3 Word: 0.016*\"donald\" + 0.014*\"market\" + 0.008*\"coronavirus\" + 0.008*\"friday\" + 0.008*\"rise\" + 0.008*\"monday\" + 0.008*\"price\" + 0.007*\"share\" + 0.007*\"christma\" + 0.007*\"australian\"\n",
      "Topic: 4 Word: 0.009*\"afl\" + 0.009*\"australia\" + 0.008*\"final\" + 0.008*\"win\" + 0.007*\"nrl\" + 0.007*\"day\" + 0.006*\"live\" + 0.006*\"beat\" + 0.006*\"open\" + 0.006*\"zealand\"\n",
      "Topic: 5 Word: 0.011*\"border\" + 0.009*\"morrison\" + 0.008*\"stori\" + 0.008*\"updat\" + 0.007*\"coronavirus\" + 0.006*\"australia\" + 0.006*\"kill\" + 0.006*\"australian\" + 0.005*\"novemb\" + 0.005*\"cyclon\"\n",
      "Topic: 6 Word: 0.035*\"trump\" + 0.016*\"drum\" + 0.010*\"tuesday\" + 0.009*\"michael\" + 0.007*\"coal\" + 0.006*\"gas\" + 0.005*\"rape\" + 0.005*\"new\" + 0.005*\"happen\" + 0.005*\"cancer\"\n",
      "Topic: 7 Word: 0.023*\"news\" + 0.014*\"abc\" + 0.012*\"rural\" + 0.009*\"climat\" + 0.009*\"thursday\" + 0.008*\"nation\" + 0.007*\"speak\" + 0.007*\"peter\" + 0.007*\"sport\" + 0.007*\"alan\"\n",
      "Topic: 8 Word: 0.025*\"coronavirus\" + 0.015*\"covid\" + 0.009*\"govern\" + 0.009*\"health\" + 0.008*\"countri\" + 0.008*\"nsw\" + 0.007*\"hour\" + 0.006*\"new\" + 0.005*\"case\" + 0.005*\"care\"\n",
      "Topic: 9 Word: 0.010*\"bushfir\" + 0.009*\"wednesday\" + 0.007*\"leagu\" + 0.006*\"world\" + 0.006*\"weather\" + 0.006*\"andrew\" + 0.006*\"septemb\" + 0.006*\"cup\" + 0.005*\"onlin\" + 0.005*\"april\"\n"
     ]
    }
   ],
   "source": [
    "# id2word: mapping from words to ids \n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=word_dict, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the LDA model on an unseen headline \n",
    "\n",
    "* Print the probability of this unseen headline belonging to this 10 topics and 5 words that defined those topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T05:01:39.786039Z",
     "iopub.status.busy": "2021-05-26T05:01:39.785660Z",
     "iopub.status.idle": "2021-05-26T05:01:39.803405Z",
     "shell.execute_reply": "2021-05-26T05:01:39.802119Z",
     "shell.execute_reply.started": "2021-05-26T05:01:39.785991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.45529210567474365\t Topic: 0.016*\"donald\" + 0.014*\"market\" + 0.008*\"coronavirus\" + 0.008*\"friday\" + 0.008*\"rise\"\n",
      "Score: 0.24213731288909912\t Topic: 0.023*\"news\" + 0.014*\"abc\" + 0.012*\"rural\" + 0.009*\"climat\" + 0.009*\"thursday\"\n",
      "Score: 0.1858055591583252\t Topic: 0.021*\"man\" + 0.018*\"polic\" + 0.015*\"charg\" + 0.013*\"murder\" + 0.012*\"woman\"\n",
      "Score: 0.01668430119752884\t Topic: 0.025*\"coronavirus\" + 0.015*\"covid\" + 0.009*\"govern\" + 0.009*\"health\" + 0.008*\"countri\"\n",
      "Score: 0.016681842505931854\t Topic: 0.011*\"border\" + 0.009*\"morrison\" + 0.008*\"stori\" + 0.008*\"updat\" + 0.007*\"coronavirus\"\n",
      "Score: 0.01668153516948223\t Topic: 0.010*\"royal\" + 0.010*\"elect\" + 0.008*\"commiss\" + 0.007*\"financ\" + 0.007*\"scott\"\n",
      "Score: 0.016680486500263214\t Topic: 0.035*\"trump\" + 0.016*\"drum\" + 0.010*\"tuesday\" + 0.009*\"michael\" + 0.007*\"coal\"\n",
      "Score: 0.01667928136885166\t Topic: 0.016*\"coast\" + 0.016*\"north\" + 0.016*\"south\" + 0.015*\"interview\" + 0.011*\"gold\"\n",
      "Score: 0.01667889393866062\t Topic: 0.010*\"bushfir\" + 0.009*\"wednesday\" + 0.007*\"leagu\" + 0.006*\"world\" + 0.006*\"weather\"\n",
      "Score: 0.01667867787182331\t Topic: 0.009*\"afl\" + 0.009*\"australia\" + 0.008*\"final\" + 0.008*\"win\" + 0.007*\"nrl\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = word_dict.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
